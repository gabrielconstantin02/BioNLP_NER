Prepare input for model:
    - tokenize and duplicate labels for subtokens
    - pad input until max_length

Models to train:
    - BERT base-uncased for baseline
    - Bert base-cased
    - RoBERTa
    - BERTNER
    - DeBERT
    - BioBERT-base-cased-v1.2
    - Distil-BioBERT 

Refactor:
    ----------------------- Rename train params to correspond to dataset
    ----------------------- Refactor predict (with test data)
    ----------------------- Add some arugments from the command line--